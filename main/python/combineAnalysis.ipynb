{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, re, csv\n",
    "import numpy as np\n",
    "import MLData,MLMethod\n",
    "#for features and labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "#for analysis methods\n",
    "from sklearn import svm\n",
    "#for evaluation\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#======================================\n",
    "# Get data for analysis\n",
    "#======================================\n",
    "# Get Raw Data From Dataset\n",
    "#ilpddatafiledir = '/afs/inf.ed.ac.uk/user/s14/s1458248/workspace/vinlccanalysissystem/src/main/resources/ilpddata/ilpddata2.csv'\n",
    "ilpddatafiledir = '/Users/cancui/workspace/virENV/lccanalysissystem/src/main/resources/ilpddata/ilpddata2.csv'\n",
    "ilpddata =MLData.get_ilpddata(ilpddatafiledir)\n",
    "biodata_patterns=[]\n",
    "for i in ilpddata:\n",
    "    biodata_patterns=biodata_patterns+[i[0:10]]\n",
    "interdata_patterns= MLData.get_interdata_patterns_sim(ilpddata)\n",
    "\n",
    "#=======================================\n",
    "# Interaction data analysis\n",
    "#=======================================    \n",
    "num_clusters=2\n",
    "biodata=MLMethod.label_biodata(num_clusters,interdata_patterns,biodata_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint scores\\nprint accuracy_score(svm_bio_test_labels,svmclfresult)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==========================================================\n",
    "# bio information classification\n",
    "#==========================================================\n",
    "\n",
    "#============================ SVM ================================\n",
    "ml_biodata = MLData.get_features_labels(biodata,10,0.4)\n",
    "svm_bio_train_features=ml_biodata['train_features'][:,0:10]\n",
    "svm_bio_train_labels=ml_biodata['train_labels']\n",
    "svm_bio_test_features=ml_biodata['test_features'][:,0:10]\n",
    "svm_bio_test_labels=ml_biodata['test_labels']\n",
    "\n",
    "svmclf=svm.SVC(C=1)\n",
    "svmclf.fit(svm_bio_train_features,svm_bio_train_labels)\n",
    "svmclfresult=svmclf.predict(svm_bio_test_features)\n",
    "\n",
    "scores=cross_val_score(svmclf,svm_bio_train_features,svm_bio_train_labels,cv=4)\n",
    "\n",
    "'''\n",
    "print scores\n",
    "print accuracy_score(svm_bio_test_labels,svmclfresult)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================== NN ===================================\n",
    "from sklearn import datasets, svm, linear_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import MLData\n",
    "\n",
    "# DATA\n",
    "nn_bio_train_features=ml_biodata['train_features']\n",
    "nn_bio_test_features=ml_biodata['test_features']\n",
    "nn_bio_train_labels=[]\n",
    "nn_bio_test_labels=[]\n",
    "\n",
    "for i in ml_biodata['train_labels']:\n",
    "    if i==0:\n",
    "        nn_bio_train_labels=nn_bio_train_labels+[[0,1]]\n",
    "    else:\n",
    "        nn_bio_train_labels=nn_bio_train_labels+[[1,0]]\n",
    "\n",
    "for i in ml_biodata['test_labels']:\n",
    "    if i==0:\n",
    "        nn_bio_test_labels=nn_bio_test_labels+[[0,1]]\n",
    "    else:\n",
    "        nn_bio_test_labels=nn_bio_test_labels+[[1,0]]\n",
    "\n",
    "nn_bio_train_labels=np.array(nn_bio_train_labels)\n",
    "nn_bio_test_labels=np.array(nn_bio_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Network Structure\n",
    "## variables for network\n",
    "num_features=10\n",
    "num_hidden_units_layer1=10\n",
    "num_output_units=2\n",
    "\n",
    "## input/output information\n",
    "NN_input=tf.placeholder(tf.float32,[None, num_features],name=\"NN_input\")\n",
    "NN_output=tf.placeholder(tf.float32,[None, num_output_units],name=\"NN_output\")\n",
    "\n",
    "## hidden layer1\n",
    "weight1=tf.get_variable('w1',[num_features,num_hidden_units_layer1],tf.float32)\n",
    "biase1=tf.get_variable('b1',[num_hidden_units_layer1],tf.float32)\n",
    "l1_output=tf.sigmoid(tf.matmul(NN_input,weight1)+biase1)\n",
    "\n",
    "## output layer\n",
    "weight2=tf.get_variable('w2',[num_hidden_units_layer1,num_output_units],tf.float32)\n",
    "biase2=tf.get_variable('b2',[num_output_units],tf.float32)\n",
    "output_logits=tf.matmul(l1_output,weight2)+biase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train methods\n",
    "### loss function\n",
    "cross_entropy=tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=NN_output,logits=output_logits))\n",
    "l1_regularizer=tf.contrib.layers.l1_regularizer(scale=0.1,scope=None)\n",
    "loss_fun=cross_entropy+tf.contrib.layers.apply_regularization(l1_regularizer,[weight1])\n",
    "### train method\n",
    "train_step=tf.train.GradientDescentOptimizer(0.05).minimize(loss_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Network\n",
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000):\n",
    "    batch_xs,batch_ys=(nn_bio_train_features,nn_bio_train_labels)\n",
    "    sess.run(train_step,feed_dict={NN_input:batch_xs,NN_output:batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706897\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "## test trained model\n",
    "correct_prediction=tf.equal(tf.argmax(NN_output,1),tf.argmax(output_logits,1))\n",
    "prediction_accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "train_accuracy=sess.run(prediction_accuracy,feed_dict={NN_input:nn_bio_train_features,NN_output:nn_bio_train_labels})\n",
    "test_accuracy=sess.run(prediction_accuracy,feed_dict={NN_input:nn_bio_test_features,NN_output:nn_bio_test_labels})\n",
    "\n",
    "\n",
    "# Show variable\n",
    "w1=sess.run(weight1)\n",
    "weight1_sum=np.sum(w1,axis=1)\n",
    "min_feature=np.argmin(np.abs(weight1_sum))\n",
    "\n",
    "\n",
    "print test_accuracy\n",
    "print min_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
