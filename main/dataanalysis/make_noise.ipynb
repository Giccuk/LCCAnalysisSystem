{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'balanced_accuracy_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69d711dcc8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'balanced_accuracy_score'"
     ]
    }
   ],
   "source": [
    "import random, re, csv\n",
    "import numpy as np\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simdata import *\n",
    "#from interdata_mysql_simple import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# for kmeans\n",
    "from scipy import stats\n",
    "#for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================\n",
    "# make mixdata from csv files\n",
    "#==============================================\n",
    "mixdata_sim_filedir='../resources/gamedata/mixdata_sim.csv'\n",
    "interdata_sim_filedir='../resources/gamedata/interdata_sim.csv'\n",
    "biodata_sim_filedir='../resources/gamedata/biodata_sim.csv'\n",
    "\n",
    "# mixdata: [[interdata,biodata,prelabel],...,[]]\n",
    "mixdata=np.asarray(get_mldata(mixdata_sim_filedir),dtype=float)\n",
    "\n",
    "#mixdata=np.insert(raw_mixdata,[0],mixdata_indx,axis=1)\n",
    "\n",
    "# interdata_features:4+1 biodata_feature:10+1\n",
    "interdata=np.asarray(get_mldata(interdata_sim_filedir),dtype=float)\n",
    "biodata=np.asarray(get_mldata(biodata_sim_filedir),dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "#==============================================\n",
    "#prepare features/labels for k-means\n",
    "#==============================================\n",
    "mixdata_feature=mixdata[:,0:mixdata[0].shape[0]-1]\n",
    "mixdata_feature_nd=(mixdata_feature - mixdata_feature.mean(axis=0)) / mixdata_feature.std(axis=0)\n",
    "mixdata_prelabel=mixdata[:,mixdata[0].shape[0]-1]\n",
    "#sample_indx=np.arange(raw_mixdata.shape[0]).reshape(raw_mixdata.shape[0],1)\n",
    "#indx_mixdata_nd=np.insert(mixdata_feature_nd[0:2],[0],sample_indx[0:2],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#================================\n",
    "# Cluster from kmeans\n",
    "#================================\n",
    "#make train/test lists for building cluster\n",
    "clu_train_feature,\\\n",
    "clu_test_feature,\\\n",
    "clu_train_label,\\\n",
    "clu_test_label = train_test_split(mixdata_feature_nd[:,0:4],mixdata_prelabel, test_size=.2)\n",
    "\n",
    "# build cluster from k-means\n",
    "cluster_km = KMeans(n_clusters=2, random_state=0).fit(clu_train_feature)\n",
    "\n",
    "#================================\n",
    "# Evaluation\n",
    "#================================\n",
    "#相似度检验\n",
    "#kresult=cluster_km.predict(clu_train_feature)\n",
    "#sim_km=metrics.adjusted_rand_score(kresult,clu_train_label)\n",
    "#sprint(\"similarity test: \",sim_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================\n",
    "# Classifier from SVM\n",
    "#================================\n",
    "#make train/test lists for building classifier\n",
    "cluster_result=cluster_km.predict(mixdata_feature_nd[:,0:4])\n",
    "\n",
    "clf_train_feature,\\\n",
    "clf_test_feature,\\\n",
    "clf_train_label,\\\n",
    "clf_test_label = train_test_split(mixdata_feature_nd[:,5:],cluster_result, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "# build classifier\n",
    "classifier_svm=svm.SVC(C=1).fit(clf_train_feature,clf_train_label)\n",
    "\n",
    "labels_pre_svm=classifier_svm.predict(clf_test_feature)\n",
    "\n",
    "\n",
    "#============================\n",
    "# Evaluation\n",
    "#============================\n",
    "# cross validation\n",
    "cv_svm=cross_val_score(classifier_svm,clf_train_feature,clf_train_label,cv=115)\n",
    "#print(\"cv_svm: \",cv_svm)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_svm.mean(), cv_svm.std() * 2))\n",
    "\n",
    "# normal accuracy\n",
    "#acc_svm=accuracy_score(clf_test_label,labels_pre_svm)\n",
    "#print(\"acc_svm: \",acc_svm)\n",
    "\n",
    "\n",
    "# precision\n",
    "#prn_svm=precision_score(clf_test_label,labels_pre_svm)\n",
    "#print(\"prn_svm: \",prn_svm)\n",
    "# balanced accuracy\n",
    "#bal_acc_svm=balanced_accuracy_score(clf_test_label,labels_pre_svm)\n",
    "#print(\"bal_acc_svm: \",bal_acc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================\n",
    "# make noise\n",
    "#=========================\n",
    "# name:noisydata_uni\n",
    "# fun: add uniform noise in to data\n",
    "# in: rawdata(np.array, NOT normalized), valuerange([low,high+1], range of noise)\n",
    "# out: noisydata(np.array)\n",
    "\n",
    "def get_uninoisydata(rawdata,valuerange):\n",
    "    uni_noise = np.random.randint(valuerange[0],valuerange[1],size=rawdata.size)\n",
    "    noisydata=uni_noise+rawdata\n",
    "    return noisydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================\n",
    "# add noise \n",
    "#=========================\n",
    "# name:get_uninoisylabel\n",
    "# fun: add uniform noise in to data\n",
    "# in: rawdata(np.array, NOT normalized), valuerange([low,high+1], range of noise)\n",
    "# out: noisydata(np.array)\n",
    "def get_uninoisylabel(rawlabel,noiselevel):\n",
    "    noisenum=int(noiselevel/100*rawlabel.size)\n",
    "    uninoise=np.random.randint(0,1,size=noisenum)\n",
    "    label_uninoise=np.append(uninoise,rawlabel[noisenum:])\n",
    "    return label_uninoise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiselevel=40\n",
    "#temp_tl=train_labels[0:10]\n",
    "train_labels_uninoise=get_uninoisylabel(train_labels,noiselevel) \n",
    "#============================\n",
    "#classify interata by SVM\n",
    "#============================\n",
    "\n",
    "clf_svm=svm.SVC(C=1)\n",
    "clf_svm.fit(train_features,train_labels_uninoise)\n",
    "labels_pre_svm=clf_svm.predict(test_features)\n",
    "#============================\n",
    "# Evaluation\n",
    "#============================\n",
    "\n",
    "acc_svm=accuracy_score(test_labels,labels_pre_svm)\n",
    "print(\"acc_svm:\",acc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata=test_features[0]\n",
    "noisydata=get_uninoisydata(rawdata,50)\n",
    "\n",
    "num_data=np.arange(0,noisydata.size)\n",
    "plt.plot(num_data,noisydata,'ro-',label='Noisy Data')\n",
    "plt.plot(rawdata,'bo-',label='Raw Data')\n",
    "plt.legend() # 展示图例\n",
    "plt.xlabel('Offer type') # 给 x 轴添加标签\n",
    "plt.ylabel('Offer Value') # 给 y 轴添加标签\n",
    "plt.title('Uniform Noise Analysis') # 添加图形标题\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count, bins, ignored = plt.hist(s, 2,normed=True)\n",
    "plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
    "plt.show()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bhdata=10*3, nbhdata=10*2 \n",
    "bhdata=np.append(np.arange(15,dtype=float),np.arange(20,35)).reshape(10,3)\n",
    "nbhdata=np.append(np.arange(10,11,0.1),np.arange(20,23,0.3)).reshape(10,2)\n",
    "data_indx=np.arange(1,bhdata.shape[0]+1).reshape(bhdata.shape[0],1)\n",
    "\n",
    "#alldata=[ [indx,bhdata,nhbdata],...,[] ], 10*6\n",
    "alldata=np.insert(np.insert(bhdata,[3],nbhdata,axis=1),[0],data_indx,axis=1)\n",
    "\n",
    "print(alldata[:,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(bhdata)\n",
    "kresult= kmeans.predict(bhdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "behave_features_len=3\n",
    "behave_features=simdata[:,0:behave_features_len]\n",
    "behave_features_nd = (behave_features - behave_features.mean(axis=0)) / behave_features.std(axis=0)\n",
    "\n",
    "train_features_clu,\\\n",
    "test_features_clu,\\\n",
    "train_labels_clu,\\\n",
    "test_labels_clu = train_test_split(behave_features_nd,simdata_l, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================\n",
    "# clustering by kmeans\n",
    "#========================\n",
    "\n",
    "X = np.array(train_features_clu)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kresult= kmeans.predict(test_features_clu)\n",
    "\n",
    "\n",
    "# 相似度检验\n",
    "print(\"similarity test: \",metrics.adjusted_rand_score(kresult,test_labels_clu))\n",
    "\n",
    "\n",
    "print(\"train_features_clu: \",train_features_clu)\n",
    "print(\"train_labels_clu: \",train_labels_clu)\n",
    "print(\"f_inter_nd: \",f_inter_nd)\n",
    "print(\"simdata_f: \",simdata_f)\n",
    "print(\"simdata_l: \",list(simdata_l))\n",
    "\n",
    "#=================================\n",
    "# classification by svm\n",
    "#=================================\n",
    "\n",
    "print(\"simdata: \",np.insert(simdata_f,[5],np.reshape(simdata_l,(5,1)),axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
