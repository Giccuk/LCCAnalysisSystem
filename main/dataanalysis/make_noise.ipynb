{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, re, csv\n",
    "import numpy as np\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simdata import *\n",
    "#from interdata_mysql_simple import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# for kmeans\n",
    "from scipy import stats\n",
    "#for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================\n",
    "# make mixdata from csv files\n",
    "#==============================================\n",
    "mixdata_sim_filedir='../resources/gamedata/mixdata_sim.csv'\n",
    "interdata_sim_filedir='../resources/gamedata/interdata_sim.csv'\n",
    "biodata_sim_filedir='../resources/gamedata/biodata_sim.csv'\n",
    "\n",
    "# mixdata: [[interdata,biodata,prelabel],...,[]]\n",
    "mixdata=np.asarray(get_mldata(mixdata_sim_filedir),dtype=float)\n",
    "\n",
    "#mixdata=np.insert(raw_mixdata,[0],mixdata_indx,axis=1)\n",
    "\n",
    "#interdata_features:4+1 biodata_feature:10+1\n",
    "interdata=np.asarray(get_mldata(interdata_sim_filedir),dtype=float)\n",
    "biodata=np.asarray(get_mldata(biodata_sim_filedir),dtype=float)\n",
    "\n",
    "#==============================================\n",
    "#prepare features/labels for k-means\n",
    "#==============================================\n",
    "mixdata_feature=mixdata[:,0:mixdata[0].shape[0]-1]\n",
    "mixdata_feature_nd=(mixdata_feature - mixdata_feature.mean(axis=0)) / mixdata_feature.std(axis=0)\n",
    "mixdata_prelabel=mixdata[:,mixdata[0].shape[0]-1]\n",
    "#sample_indx=np.arange(raw_mixdata.shape[0]).reshape(raw_mixdata.shape[0],1)\n",
    "#indx_mixdata_nd=np.insert(mixdata_feature_nd[0:2],[0],sample_indx[0:2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# aim: build km cluster and svm classifier from data\n",
    "# in: bhdata,nbhdata(follow natural distribution);\n",
    "#     clu_num(number of clusters)\n",
    "# out: dict={\"cluer\":cluster_km,\"clfer\":classifier_svm}\n",
    "#===================================================================================\n",
    "def build_analyser(bhdata_nd,nbhdata_nd,clu_num):\n",
    "    #Cluster from kmeans\n",
    "    cluster_km = KMeans(n_clusters=clu_num, random_state=0).fit(bhdata_nd)\n",
    "    #Classifier from SVM\n",
    "    cluster_result=cluster_km.labels_\n",
    "    clf_train_feature,\\\n",
    "    clf_test_feature,\\\n",
    "    clf_train_label,\\\n",
    "    clf_test_label = train_test_split(nbhdata_nd,cluster_result, test_size=.2)\n",
    "    # build classifier\n",
    "    classifier_svm=svm.SVC(C=1).fit(clf_train_feature,clf_train_label)\n",
    "    return {\"clu\":cluster_km,\"clf\":classifier_svm}\n",
    "\n",
    "all_anls=build_analyser(mixdata_feature_nd[:,0:4],mixdata_feature_nd[:,5:],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf2: 0.72 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "clfer=all_anls[\"clf\"]\n",
    "clker=all_anls['clu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1=clf2.predict(clf_test_feature[0].reshape(1,-1))\n",
    "pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "num_data=np.arange(0,noisydata.size)\n",
    "plt.plot(num_data,noisydata,'ro-',label='Noisy Data')\n",
    "plt.plot(rawdata,'bo-',label='Raw Data')\n",
    "plt.legend() # 展示图例\n",
    "plt.xlabel('Offer type') # 给 x 轴添加标签\n",
    "plt.ylabel('Offer Value') # 给 y 轴添加标签\n",
    "plt.title('Uniform Noise Analysis') # 添加图形标题\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================\n",
    "# add noise \n",
    "#=========================\n",
    "# name:get_uninoisylabel\n",
    "# fun: add uniform noise in to data\n",
    "# in: rawdata(np.array, NOT normalized), valuerange([low,high+1], range of noise)\n",
    "# out: noisydata(np.array)\n",
    "def get_uninoisylabel(rawlabel,noiselevel):\n",
    "    noisenum=int(noiselevel/100*rawlabel.size)\n",
    "    uninoise=np.random.randint(0,1,size=noisenum)\n",
    "    label_uninoise=np.append(uninoise,rawlabel[noisenum:])\n",
    "    return label_uninoise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiselevel=40\n",
    "#temp_tl=train_labels[0:10]\n",
    "train_labels_uninoise=get_uninoisylabel(train_labels,noiselevel) \n",
    "#============================\n",
    "#classify interata by SVM\n",
    "#============================\n",
    "\n",
    "clf_svm=svm.SVC(C=1)\n",
    "clf_svm.fit(train_features,train_labels_uninoise)\n",
    "labels_pre_svm=clf_svm.predict(test_features)\n",
    "#============================\n",
    "# Evaluation\n",
    "#============================\n",
    "\n",
    "acc_svm=accuracy_score(test_labels,labels_pre_svm)\n",
    "print(\"acc_svm:\",acc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count, bins, ignored = plt.hist(s, 2,normed=True)\n",
    "plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
    "plt.show()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bhdata=10*3, nbhdata=10*2 \n",
    "bhdata=np.append(np.arange(15,dtype=float),np.arange(20,35)).reshape(10,3)\n",
    "nbhdata=np.append(np.arange(10,11,0.1),np.arange(20,23,0.3)).reshape(10,2)\n",
    "data_indx=np.arange(1,bhdata.shape[0]+1).reshape(bhdata.shape[0],1)\n",
    "\n",
    "#alldata=[ [indx,bhdata,nhbdata],...,[] ], 10*6\n",
    "alldata=np.insert(np.insert(bhdata,[3],nbhdata,axis=1),[0],data_indx,axis=1)\n",
    "\n",
    "print(alldata[:,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(bhdata)\n",
    "kresult= kmeans.predict(bhdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.random.uniform(-1,0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "behave_features_len=3\n",
    "behave_features=simdata[:,0:behave_features_len]\n",
    "behave_features_nd = (behave_features - behave_features.mean(axis=0)) / behave_features.std(axis=0)\n",
    "\n",
    "train_features_clu,\\\n",
    "test_features_clu,\\\n",
    "train_labels_clu,\\\n",
    "test_labels_clu = train_test_split(behave_features_nd,simdata_l, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================\n",
    "# clustering by kmeans\n",
    "#========================\n",
    "\n",
    "X = np.array(train_features_clu)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kresult= kmeans.predict(test_features_clu)\n",
    "\n",
    "\n",
    "# 相似度检验\n",
    "print(\"similarity test: \",metrics.adjusted_rand_score(kresult,test_labels_clu))\n",
    "\n",
    "\n",
    "print(\"train_features_clu: \",train_features_clu)\n",
    "print(\"train_labels_clu: \",train_labels_clu)\n",
    "print(\"f_inter_nd: \",f_inter_nd)\n",
    "print(\"simdata_f: \",simdata_f)\n",
    "print(\"simdata_l: \",list(simdata_l))\n",
    "\n",
    "#=================================\n",
    "# classification by svm\n",
    "#=================================\n",
    "\n",
    "print(\"simdata: \",np.insert(simdata_f,[5],np.reshape(simdata_l,(5,1)),axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
